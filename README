prll
version 0.4.9999
===========

prll is a utility for use with bash or zsh. It provides a convenient
interface for parallelizing the execution of a single task over
multiple data files, or actually any kind of data that you can pass as
a function argument. It is meant to make it simple to fully utilize a
multicore/multiprocessor machine.

Homepage: http://prll.sourceforge.net/


DESCRIPTION
-----------

prll is designed to be used not just in shell scripts, but especially
in interactive shells. To make the latter convenient, it is
implemented as a shell function. Shells are not much good at automatic
job management; see [1] for further discussion. Therefore, prll uses
helper programs, written in C. To prevent race conditions, System V
Message Queues and Semaphores are used to signal job completion. It
also features full output buffering to prevent mangling of data
because of concurrent output.

[1] http://prll.sourceforge.net/shell_parallel.html


REQUIREMENTS
------------

  - bash or zsh
  - C compiler, such as gcc
  - OS support for System V Message Queues and Semaphores
  - device files /dev/urandom or /dev/random
  - the cat utility
  - optional tests require utilites tr, grep, sort, split,
    sed, diff and uname

Systems tested: GNU/Linux, FreeBSD, OpenBSD, MacOS X

These requirements should be satisfied by your system by default,
excepting perhaps the compiler and its toolchain, which are not
installed by default on systems such as Ubuntu Linux. Refer to your
system's documentation on how to install missing programs.

prll also looks for the /proc/cpuinfo file. It uses it to
automatically determine the number of processors. Non-Linux systems
may lack this file or have a different syntax. Setting the
PRLL_NR_CPUS environment variable renders the cpuinfo file unnecessary
(see usage instructions below).

Linux systems that were tested had much larger Message Queue size than
non-Linux systems. Queue size dictates the maximum number of jobs that
can be run in parallel. A rule of thumb: a BSD system can run about 20
jobs, depending on the number of existing queues, while a Linux system
can run over 500 jobs; at that point, the shell's job table becomes
saturated.

INSTALLATION
------------

Compile prll_qer.c. You can use the included Makefile. If you
have gcc, you can simply run

  make

If you have gcc and want different compiler options, do

  CFLAGS=whatever make

If you have a different compiler, you may want to completely override
compiler options, like so

  make CFLAGS=whatever

You may wish to run 'make test' at this point. It will do some simple
tests to verify that prll produces correct results. The test suite is
not comprehensive, however, and is itself not well tested, so you
should try prll on real-world data before coming to any
conclusions. Failure is not necessarily meaningful, either. For
example, if there are already several message queues being used on
your system, you may be running out of IPC memory. That would cause
some tests to fail or hang (in fact, some are disabled on non-Linux
systems for this reason), while it wouldn't interfere with normal
operation as long as you don't run too many parallel jobs. Also, be
aware that full testing requires about 100MB disk space.

When prll is built, copy the prll_qer and prll_bfr executables to a
directory you have in your PATH. For example, to do a system-wide
installation, run as root

  chown root:root prll_qer prll_bfr
  cp prll_qer prll_bfr /usr/local/bin/

File prll.sh contains the shell function. The shell that will use it
needs to source it. That means that:
  - If you wish to use prll in a shell script, simply copy it in there.
  - If you wish to use prll in an interactive shell, source it.
The latter means that you need to put the function somewhere where
your shell will find it. If you are installing it for yourself, put
it in your .bashrc or .zshrc. If you are installing it system-wide, put
it in /etc/profile. However, if your system has the /etc/profile.d
directory, use that. For example

  chown root:root prll.sh
  cp prll.sh /etc/profile.d/

The function should now be automatically sourced by login shells. To
have every shell source it instead of only login shells, insert

  source /etc/profile

into your .bashrc or .zshrc.


USAGE
-----

Synopsis: prll [-b] function_name arguments ...
	  prll [-b] -s 'code' arguments ...

Order of options is important.

To execute a task, create a shell function that does something to its
first argument. Pass that function to prll along with the arguments
you wish to execute it on.

As an alternative, you may pass the '-s' flag, followed by a
string. The string will be executed as if it were the body of a shell
function. Therefore, you may use $1 to reference it's first parameter.

Instead of arguments, you can use flags '-p' or '-0'. prll will then
take it's arguments from stdin. The '-p' flag will make it read lines
and the '-0' flag will make it read null-delimited input. This mode
emulates the 'xargs' utility a bit, but is easier for interactive use
because xargs makes it hard to pass complex commands.

The '-b' option disables output buffering. See below for explanation.

The number of tasks to be run in parallel is provided via the
PRLL_NR_CPUS environment variable. If it is not provided, prll will
look into the /proc/cpuinfo file and extract the number of CPUs in
your computer.

If you need to abort execution, you can do it with the usual Ctrl+C
key combination. prll will wait for remaining jobs to complete before
exiting. You can force termination by typing Ctrl+C once more. The
jobs' PIDs are printed during execution so you can easily track them
down and terminate them if necessary. prll will not do it
automatically because only you can decide whether they are still doing
useful work or not. Also, jobs print completion notifications on their
own so you will know when they are done even if prll itself is
terminated. Should that be the case, they will also print a harmless
'file not found' message because the message queue will be removed.

The command 'prll_interrupt' is available from within your
functions. It causes prll to abort execution in the same way as
described above.

prll cleans after itself, but if you are worried about stale message
queues or semaphores, you can list them with the 'ipcs' command and
remove them with the 'ipcrm' command. Refer to your system's
documentation for details.

IMPORTANT:

prll does internal output buffering by default. This is to prevent
interleaving of several jobs' outputs and thus mangling of data. Each
job has its own buffer into which it writes, and these buffers make
sure that at most one job writes to standard output at any one
time. This buffer is not limited in size, and might read all data that
a job writes. Therefore, if your jobs print a lot of data on standard
output, they will consume A LOT OF MEMORY.

If your jobs print a lot of data, you need to redirect each job's
standard output to a file, and each job needs it's own file. In that
case, everything will be fine. It complicates writing the shell
function, though. If you believe that each of your jobs will output
only a small amount of data (up to 4kB on Linux, it depends on the
size of your OS' pipe buffer) but you are afraid that errors might
creep in and cause spurious output, you can avoid accidental memory
hogging by disabling buffering with the '-b' option.

Let it be clear that this size limitation applies to the individual
job's output. It does not concern the size of the whole output.

Standard error is not buffered and will not cause memory consumption.


Examples:

Suppose you have a set of photos that you wish to process using the
'mogrify' utility. Simply do

  function myfn() { mogrify -flip $1 ; }
  prll myfn *.jpg

This will run mogrify on each jpg file in the current directory. If
your computer has 4 processors, but you wish to run only 3 tasks at
once, you should use

  PRLL_NR_CPUS=3 prll myfn *.jpg

Or, to make it permanent in the current shell, do

  export PRLL_NR_CPUS=3


To make things shorter, you can leave out the 'function' keyword when
defining a function. To redefine the same example:

  myfn() { mogrify -flip $1 ; }

However, you now need to be careful not to forget the parentheses. When
using the 'function' keyword, they are optional. If you leave it out,
they are not.

All examples here are very short. In practice, it is quicker to pass
such a short function on the command line directly:

  prll -s 'mogrify -flip $1' *.jpg

prll now automatically wraps the code in an internal function so you
don't have to. Don't forget about the single quotes, or the shell will
expand $1 before prll is run.


If you have a more complicated function that has to take more than one
argument, you should use a trick: combine multiple arguments into one
when passing them to prll, then split them again inside your
function. Here is a stub for a function that takes three arguments:

  # for zsh only
  function myfn() { echo $1 | read a b c; process $a; compute $b; kill $c; }
  # for both bash and zsh
  function myfn() { read a b c <<<$1 ; process $a; compute $b; kill $c; }
  prll myfn 'a1 b1 c1' 'a2 b2 c3' 'a3 b3 c3' ...


You may wish to abort execution if one of the results is wrong. In
that case, use something like this:

     function myfn() { compute $1; [[ $result == "wrong" ]] && prll_interrupt; }


If you have many arguments to process, it might be easier to pass them
on standard input. Suppose each line of a file is an argument of its
own. Simply pipe the file into prll:

  function myfn() { some; processing | goes && on; here; }
  cat file_with_arguments | prll myfn -p > results


KNOWN ISSUES
------------

This section describes issues and bugs that were known at the time of
release. For more current information, check the newer version of this
file. You can find it in the project's git repository:

  http://prll.git.sourceforge.net/git/gitweb.cgi?p=prll/prll;a=tree

There, you will find out which new issues were found and which of the
old issues were fixed. If you have an issue that is not described,
check the git log if it was ever found and fixed. If not, please
contact the author. Suggestions are welcome, patches even more so.


Known issues:

- Expand the test suite.
  Specifically, termination behaviour on external interrupt signal
  currently has to be checked manually. Also, checking of stderr
  output is not done.

- Document cross-compilation and make it easier to cross-compile.

- Shell's job table becomes saturated with a large number of jobs.
  This is not really an issue, since it happens when the number of
  jobs is above 500 or so. Nevertheless, it might be possible to
  disown jobs if such a large number of them should be required.


LICENSING INFORMATION
---------------------

The prll package is provided under the GNU General Public
License, version 3 or later. See COPYING for more information.

Copyright 2009-2010 Jure Varlec
